{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# The tale of the deep learning model that failed my driving exam\n",
    "\n",
    "It’s exam day, and you are the driving evaluator. Two very different \"drivers\" are up for their final test, and it’s your job to determine if they’re ready for a driving license. The first candidate is a teenager, Sarah—she’s about 18, a little nervous but focused. The second \"driver\" is not a person at all; it’s a deep learning model based on a massive Transformer architecture, trained to predict driving actions like turning, braking, and accelerating based on live HD camera input.\n",
    "\n",
    "You take both out on a pre-defined driving circuit, where they’ll need to handle basic maneuvers. But there’s one test you’re particularly interested in—a tricky intersection with a catch: the light turns yellow, and just as they approach, an ambulance is speeding through, despite the green light for the other lanes.\n",
    "\n",
    "You ride with Sarah first. As you near the intersection, the light shifts to yellow, and the ambulance cuts across. Sarah reacts quickly, easing the car to a stop. You’re pleased—she’s cautious, and made the right call.\n",
    "\n",
    "Next, you get into the vehicle controlled by the deep learning model. The system, connected to the car's camera, processes the scene in real-time. It, too, stops smoothly as the ambulance passes, seemingly making the correct decision. You feel a sense of relief—both drivers handled the situation perfectly.\n",
    "\n",
    "However, you are a stickler for details. Stopping was the right move, but did they both do it for the right reasons? Was it understanding or just luck? To find out, you turn to your post-drive evaluation questions, aimed at revealing the drivers’ thought processes.\n",
    "\n",
    "You start with Sarah. “What did you see at the intersection?” you ask.\n",
    "\n",
    "“I saw the intersection, the yellow light, and an ambulance trying to cross,” she answers confidently. She identified all the key points, and you’re reassured, but you dig deeper.\n",
    "\n",
    "“And what do you usually do when you're in a similar situation, but the light is green?”\n",
    "\n",
    "Sarah laughs softly. “Well, it doesn’t really matter if the light is green or yellow—the ambulance is more important.”\n",
    "\n",
    "Her answer is spot-on. You feel your tension ease, and you proceed with the final question. “What would need to change for you to go ahead and cross?”\n",
    "\n",
    "“If the ambulance hadn’t been there, I would’ve crossed,” she says without hesitation.\n",
    "\n",
    "Satisfied with Sarah's clear reasoning, you grant her the driving license. She clearly understood the situation and can explain her actions, she'll be a cautious driver.\n",
    "\n",
    "Now it’s the deep learning model’s turn. You turn to your AI expert friend for help in interpreting the model’s responses. “What did the model see?” you ask your friend.\n",
    "\n",
    "Your friend taps into the system and pulls up the exact HD image the model processed—an incredibly detailed capture of the intersection. You can see everything down to the fur of a nearby dog, but something about it feels vague. You don’t yet know why the model stopped, so you press on.\n",
    "\n",
    "Next, you ask, “What does the model usually do in similar situations when something changes in that image?”\n",
    "\n",
    "Your friend types a query into the system and quickly explains to you that \"when the mean activation of input embedding block 42 is above 173, the model usually stops\".\n",
    "\n",
    "You frown, confused. What does that have to do with stopping for an ambulance? The explanation feels disconnected from the real-world reasoning you’re used to hearing. But you move to the final question, hoping for clarity.\n",
    "\n",
    "“What should have changed in that image for the model to decide to cross instead?”\n",
    "\n",
    "Your friend checks again and pulls up another set of numbers. “Should the pixel 2890 of the original image had an RGB value of (28, 178, 111), the model would have chosen to cross” he says.\n",
    "\n",
    "You’re at a loss. The model’s response is technical, tied to pixel values and activations, rather than an understanding of traffic rules or emergency vehicles. It stopped, yes, but did it truly understand why? Or was it just acting based on patterns it had seen before?\n",
    "\n",
    "As you sit there, contemplating, the question lingers in your mind: would you give the deep learning model a driving license?\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
